{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e7b14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in d:\\github\\blockchain-smart-contract-security\\.venv\\lib\\site-packages (2.3.0+cu118)\n",
      "Requirement already satisfied: torchvision in d:\\github\\blockchain-smart-contract-security\\.venv\\lib\\site-packages (0.18.0+cu118)\n",
      "Requirement already satisfied: torchaudio in d:\\github\\blockchain-smart-contract-security\\.venv\\lib\\site-packages (2.3.0+cu118)\n",
      "Requirement already satisfied: filelock in d:\\github\\blockchain-smart-contract-security\\.venv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\github\\blockchain-smart-contract-security\\.venv\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in d:\\github\\blockchain-smart-contract-security\\.venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\github\\blockchain-smart-contract-security\\.venv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\github\\blockchain-smart-contract-security\\.venv\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in d:\\github\\blockchain-smart-contract-security\\.venv\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in d:\\github\\blockchain-smart-contract-security\\.venv\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in d:\\github\\blockchain-smart-contract-security\\.venv\\lib\\site-packages (from torchvision) (1.26.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\github\\blockchain-smart-contract-security\\.venv\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in d:\\github\\blockchain-smart-contract-security\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in d:\\github\\blockchain-smart-contract-security\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\github\\blockchain-smart-contract-security\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\github\\blockchain-smart-contract-security\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a49e9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76e4edff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "415baf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu118\n",
      "True\n",
      "NVIDIA GeForce RTX 2060\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e8b5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 9900\n",
      "Sample data: ('function transfer ( address _to , uint256 _value ) public returns ( bool success ) ; function transferFrom ( address _from , address _to , uint256 _value ) public returns ( bool success ) ; function approve ( address _spender , uint256 _value ) public returns ( bool success ) ; function allowance ( address _owner , address _spender ) public constant returns ( uint256 remaining ) ; event Transfer ( address indexed _from , address indexed _to , uint256 _value ) ; event Approval ( address indexed _owner , address indexed _spender , uint256 _value ) ; } contract GTO is ERC20Interface { uint8 public constant decimals = 5 ; string public constant symbol = GTO ; string public constant name = GTO ; bool public _selling = false ; uint256 public _totalSupply = 10 * * 14 ; uint256 public _originalBuyPrice = 45 * 10 * * 7 ; address public owner ; mapping ( address = > uint256 ) private balances ; mapping ( address = > mapping ( address = > uint256 ) ) private allowed ; mapping ( address = > bool ) private approvedInvestorList ; mapping ( address = > uint256 ) private deposit ; address [ ] private buyers ; uint8 public _icoPercent = 10 ; uint256 public _icoSupply = _totalSupply * _icoPercent / 100 ; uint256 public _minimumBuy = 3 * 10 * * 17 ; uint256 public _maximumBuy = 30 * 10 * * 18 ; modifier onlyOwner ( ) { require ( msg . sender = = owner ) ; _ ; }', 0)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Kết nối tới MongoDB và truy vấn dữ liệu\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['Interaction_and_Contract_State_Vulnerabilities']\n",
    "\n",
    "vulnerabilities = ['reentrancy', 'delegatecall', 'unchecked_external_call', 'unchecked_send']\n",
    "labels = {vulnerability: i for i, vulnerability in enumerate(vulnerabilities)}\n",
    "data = []\n",
    "\n",
    "def fetch_data_from_collection(collection_name, label):\n",
    "    collection = db[collection_name]\n",
    "    documents = collection.find({})\n",
    "    for doc in documents:\n",
    "        if 'extract_feature' in doc:\n",
    "            for feature in doc['extract_feature']:\n",
    "                tokens = feature.get('tokens', [])\n",
    "                if tokens:\n",
    "                    data.append((' '.join(tokens), label))\n",
    "\n",
    "for vulnerability in vulnerabilities:\n",
    "    fetch_data_from_collection(vulnerability, labels[vulnerability])\n",
    "\n",
    "print(f\"Number of samples: {len(data)}\")\n",
    "if data:\n",
    "    print(f\"Sample data: {data[8]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a27943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Định nghĩa lớp SolidityDataset\n",
    "class SolidityDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text, label = self.data[index]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f3b4086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum token length: 1006\n",
      "Longest token sequence: function createNew ( bytes32 _regName , address _owner ) payable returns ( address kAddr_ ) ; } pragma solidity 0 . 4 . 10 ; contract BaktInterface { struct Holder { uint8 id ; address votingFor ; uint40 offerExpiry ; uint lastClaimed ; uint tokenBalance ; uint etherBalance ; uint votes ; uint offerAmount ; mapping ( address = > uint ) allowances ; } struct TX { bool blocked ; uint40 timeLock ; address from ; address to ; uint value ; bytes data ; } uint constant MAXTOKENS = 2 * * 128 - 10 * * 18 ; uint constant MAXETHER = 2 * * 128 ; uint constant BLOCKPCNT = 10 ; uint constant TOKENPRICE = 1000000000000000 ; uint8 public constant decimalPlaces = 15 ; bool __reMutex ; bool __initFuse = true ; bool public acceptingPayments ; uint40 public PANICPERIOD ; uint40 public TXDELAY ; bool public panicked ; uint8 public ptxHead ; uint8 public ptxTail ; uint40 public timeToCalm ; address public trustee ; uint public totalSupply ; uint public committedEther ; uint dividendPoints ; uint public totalDividends ; bytes32 public regName ; bytes32 public resource ; mapping ( address = > Holder ) public holders ; address [ 256 ] public holderIndex ; TX [ 256 ] public pendingTxs ; event Deposit ( uint value ) ; event Withdrawal ( address indexed sender , address indexed recipient , uint value ) ; event TransactionPending ( uint indexed pTX , address indexed sender , address indexed recipient , uint value , uint timeLock ) ; event TransactionBlocked ( address indexed by , uint indexed pTX ) ; event TransactionFailed ( address indexed sender , address indexed recipient , uint value ) ; event DividendPaid ( uint value ) ; event Transfer ( address indexed from , address indexed to , uint value ) ; event Approval ( address indexed owner , address indexed spender , uint value ) ; event Trustee ( address indexed trustee ) ; event NewHolder ( address indexed holder ) ; event HolderVacated ( address indexed holder ) ; event IssueOffer ( address indexed holder ) ; event TokensCreated ( address indexed holder , uint amount ) ; event TokensDestroyed ( address indexed holder , uint amount ) ; event Panicked ( address indexed by ) ; event Calm ( ) ; function ( ) payable ; function _init ( uint40 _panicDelayInSeconds , uint40 _pendingDelayInSeconds ) returns ( bool ) ; function fundBalance ( ) constant returns ( uint ) ; function tokenPrice ( ) constant returns ( uint ) ; function balanceOf ( address _addr ) constant returns ( uint ) ; function transfer ( address _to , uint _amount ) returns ( bool ) ; function transferFrom ( address _from , address _to , uint256 _amount ) returns ( bool ) ; function approve ( address _spender , uint256 _amount ) returns ( bool ) ; function allowance ( address _owner , address _spender ) constant returns ( uint256 ) ; function PANIC ( ) returns ( bool ) ; function calm ( ) returns ( bool ) ; function sendPending ( ) returns ( bool ) ; function blockPendingTx ( uint _txIdx ) returns ( bool ) ; function execute ( address _to , uint _value , bytes _data ) returns ( uint8 ) ; function payDividends ( uint _value ) returns ( bool ) ; function getHolders ( ) constant returns ( address [ 256 ] ) ; function etherBalanceOf ( address _addr ) constant returns ( uint ) ; function withdraw ( ) returns ( uint8 ) ; function vacate ( address _addr ) returns ( bool ) ; function purchase ( ) payable returns ( bool ) ; function redeem ( uint _amount ) returns ( bool ) ; function vote ( address _candidate ) returns ( bool ) ; } contract Bakt is BaktInterface { bytes32 constant public VERSION = Bakt 0 . 3 . 4 - beta ; function Bakt ( address _creator , bytes32 _regName , address _trustee ) { regName = _regName ; trustee = _trustee ! = 0x0 _trustee _creator ! = 0x0 _creator msg . sender ; join ( trustee ) ; }\n"
     ]
    }
   ],
   "source": [
    "# Determine the maximum token length\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "token_lengths = [len(tokenizer.encode(text, add_special_tokens=True)) for text, _ in data]\n",
    "MAX_LEN = max(token_lengths)\n",
    "longest_token_sequence = data[token_lengths.index(MAX_LEN)][0]\n",
    "\n",
    "print(f\"Maximum token length: {MAX_LEN}\")\n",
    "print(f\"Longest token sequence: {longest_token_sequence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dfb1f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum token length: 1006\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Chuẩn bị dữ liệu và dataloader\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "if data:\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    train_dataset = SolidityDataset(train_data, tokenizer, MAX_LEN)\n",
    "    test_dataset = SolidityDataset(test_data, tokenizer, MAX_LEN)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "else:\n",
    "    print(\"No data available to split into training and test sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33515aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab60c6751b448cf85a9a64133104627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Khởi tạo mô hình và các tham số huấn luyện\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Định nghĩa các siêu tham số của mô hình BERT\n",
    "config = BertConfig(\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    hidden_dropout_prob=0.2,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    max_position_embeddings=512,\n",
    "    num_labels=len(vulnerabilities)\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)\n",
    "model = model.to(device)\n",
    "\n",
    "EPOCHS = 13\n",
    "LEARNING_RATE = 2e-5\n",
    "EPSILON = 1e-4\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, eps=EPSILON)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3944f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Định nghĩa hàm train_epoch và eval_model\n",
    "def train_epoch(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", unit=\"batch\")\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.set_postfix({\"Loss\": loss.item()})\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def eval_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    progress_bar = tqdm(dataloader, desc=\"Evaluating\", unit=\"batch\")\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            progress_bar.set_postfix({\"Loss\": loss.item(), \"Accuracy\": correct_predictions.item() / len(dataloader.dataset)})\n",
    "    return total_loss / len(dataloader), correct_predictions.double() / len(dataloader.dataset), all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab9c57ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true_labels, predicted_labels):\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf9ec16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 495/495 [02:29<00:00,  3.32batch/s, Loss=0.16]  \n",
      "Evaluating: 100%|██████████| 124/124 [00:13<00:00,  9.23batch/s, Loss=0.193, Accuracy=0.951]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2944\n",
      "Validation Loss: 0.1115, Validation Accuracy: 0.9505\n",
      "Epoch 2/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 495/495 [02:30<00:00,  3.29batch/s, Loss=0.0902] \n",
      "Evaluating: 100%|██████████| 124/124 [00:13<00:00,  9.46batch/s, Loss=0.112, Accuracy=0.958]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1128\n",
      "Validation Loss: 0.0875, Validation Accuracy: 0.9581\n",
      "Epoch 3/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 495/495 [02:30<00:00,  3.28batch/s, Loss=0.0877] \n",
      "Evaluating: 100%|██████████| 124/124 [00:12<00:00,  9.83batch/s, Loss=0.23, Accuracy=0.959]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1022\n",
      "Validation Loss: 0.0865, Validation Accuracy: 0.9591\n",
      "Epoch 4/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  31%|███       | 153/495 [00:45<01:42,  3.33batch/s, Loss=0.232]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     val_loss, val_acc, _, _ \u001b[38;5;241m=\u001b[39m eval_model(model, test_dataloader, device)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, dataloader, optimizer, device)\u001b[0m\n\u001b[0;32m     11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, labels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[0;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m---> 13\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Huấn luyện mô hình\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, device)\n",
    "    val_loss, val_acc, _, _ = eval_model(model, test_dataloader, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "test_loss, test_acc, test_labels, test_preds = eval_model(model, test_dataloader, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Sử dụng hàm evaluate_model để tính các chỉ số đánh giá\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "evaluate_model(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb55d54d",
   "metadata": {},
   "source": [
    "nguyên bản\n",
    "Epoch 1/13\n",
    "Training: 100%|██████████| 495/495 [02:35<00:00,  3.19batch/s, Loss=0.119] \n",
    "Evaluating: 100%|██████████| 124/124 [00:14<00:00,  8.68batch/s, Loss=0.487, Accuracy=0.951] \n",
    "Train Loss: 0.2832\n",
    "Validation Loss: 0.1256, Validation Accuracy: 0.9505\n",
    "Epoch 2/13\n",
    "Training: 100%|██████████| 495/495 [03:17<00:00,  2.51batch/s, Loss=0.0807] \n",
    "Evaluating: 100%|██████████| 124/124 [00:17<00:00,  7.29batch/s, Loss=0.406, Accuracy=0.952]  \n",
    "Train Loss: 0.1184\n",
    "Validation Loss: 0.0931, Validation Accuracy: 0.9515\n",
    "Epoch 3/13\n",
    "Training: 100%|██████████| 495/495 [03:10<00:00,  2.60batch/s, Loss=0.155]  \n",
    "Evaluating: 100%|██████████| 124/124 [00:16<00:00,  7.43batch/s, Loss=0.22, Accuracy=0.957]   \n",
    "Train Loss: 0.0991\n",
    "Validation Loss: 0.0855, Validation Accuracy: 0.9571\n",
    "Epoch 4/13\n",
    "Training: 100%|██████████| 495/495 [02:53<00:00,  2.86batch/s, Loss=0.112]  \n",
    "Evaluating: 100%|██████████| 124/124 [00:14<00:00,  8.39batch/s, Loss=0.52, Accuracy=0.958]    \n",
    "Train Loss: 0.0920\n",
    "Validation Loss: 0.0845, Validation Accuracy: 0.9581\n",
    "Epoch 5/13\n",
    "Training: 100%|██████████| 495/495 [02:49<00:00,  2.92batch/s, Loss=0.173]   \n",
    "Evaluating: 100%|██████████| 124/124 [00:15<00:00,  7.82batch/s, Loss=0.586, Accuracy=0.958]   \n",
    "Train Loss: 0.0880\n",
    "Validation Loss: 0.0833, Validation Accuracy: 0.9576\n",
    "Epoch 6/13\n",
    "Training: 100%|██████████| 495/495 [02:49<00:00,  2.92batch/s, Loss=0.0619]  \n",
    "Evaluating: 100%|██████████| 124/124 [00:14<00:00,  8.33batch/s, Loss=0.179, Accuracy=0.959]   \n",
    "Train Loss: 0.0856\n",
    "Validation Loss: 0.0779, Validation Accuracy: 0.9591\n",
    "Epoch 7/13\n",
    "Training: 100%|██████████| 495/495 [02:49<00:00,  2.92batch/s, Loss=0.0573]  \n",
    "Evaluating: 100%|██████████| 124/124 [00:16<00:00,  7.54batch/s, Loss=0.149, Accuracy=0.959]   \n",
    "Train Loss: 0.0905\n",
    "Validation Loss: 0.0783, Validation Accuracy: 0.9591\n",
    "Epoch 8/13\n",
    "Training: 100%|██████████| 495/495 [03:31<00:00,  2.34batch/s, Loss=0.0554]  \n",
    "Evaluating: 100%|██████████| 124/124 [00:18<00:00,  6.87batch/s, Loss=0.188, Accuracy=0.959]   \n",
    "Train Loss: 0.0840\n",
    "Validation Loss: 0.0786, Validation Accuracy: 0.9591\n",
    "Epoch 9/13\n",
    "Training: 100%|██████████| 495/495 [02:44<00:00,  3.01batch/s, Loss=0.000331]\n",
    "Evaluating: 100%|██████████| 124/124 [00:14<00:00,  8.84batch/s, Loss=0.129, Accuracy=0.959]   \n",
    "Train Loss: 0.0840\n",
    "Validation Loss: 0.0848, Validation Accuracy: 0.9591\n",
    "Epoch 10/13\n",
    "Training: 100%|██████████| 495/495 [02:36<00:00,  3.16batch/s, Loss=0.139]   \n",
    "Evaluating: 100%|██████████| 124/124 [00:13<00:00,  8.98batch/s, Loss=0.552, Accuracy=0.956]   \n",
    "Train Loss: 0.0834\n",
    "Validation Loss: 0.0895, Validation Accuracy: 0.9556\n",
    "Epoch 11/13\n",
    "Training: 100%|██████████| 495/495 [02:34<00:00,  3.20batch/s, Loss=0.0348]  \n",
    "Evaluating: 100%|██████████| 124/124 [00:13<00:00,  8.89batch/s, Loss=0.612, Accuracy=0.959]   \n",
    "Train Loss: 0.0893\n",
    "Validation Loss: 0.0846, Validation Accuracy: 0.9586\n",
    "Epoch 12/13\n",
    "Training: 100%|██████████| 495/495 [02:38<00:00,  3.12batch/s, Loss=0.076]   \n",
    "Evaluating: 100%|██████████| 124/124 [00:15<00:00,  7.94batch/s, Loss=0.508, Accuracy=0.959]   \n",
    "Train Loss: 0.0831\n",
    "Validation Loss: 0.0871, Validation Accuracy: 0.9586\n",
    "Epoch 13/13\n",
    "Training: 100%|██████████| 495/495 [02:41<00:00,  3.06batch/s, Loss=0.000251]\n",
    "Evaluating: 100%|██████████| 124/124 [00:13<00:00,  8.94batch/s, Loss=0.825, Accuracy=0.959]   \n",
    "Train Loss: 0.0811\n",
    "Validation Loss: 0.0991, Validation Accuracy: 0.9586\n",
    "Evaluating: 100%|██████████| 124/124 [00:13<00:00,  8.87batch/s, Loss=0.825, Accuracy=0.959]   \n",
    "Test Loss: 0.0991, Test Accuracy: 0.9586\n",
    "\n",
    "Evaluation Metrics:\n",
    "Accuracy: 0.9585858585858585\n",
    "Precision: 0.970213318259917\n",
    "Recall: 0.9585858585858585\n",
    "F1-score: 0.9608064022546272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff54e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc883941",
   "metadata": {},
   "source": [
    "chia mutil head ra  \n",
    "Epoch 1/13\n",
    "Training: 100%|███████████████████████████████████████████████████████████████████████████████| 495/495 [02:21<00:00,  3.50batch/s, Loss=0.355] \n",
    "Evaluating: 100%|█████████████████████████████████████████████████████████████| 124/124 [00:12<00:00, 10.26batch/s, Loss=0.119, Accuracy=0.947] \n",
    "Train Loss: 0.3042\n",
    "Validation Loss: 0.1342, Validation Accuracy: 0.9475\n",
    "Epoch 2/13\n",
    "Training: 100%|███████████████████████████████████████████████████████████████████████████████| 495/495 [02:22<00:00,  3.49batch/s, Loss=0.139] \n",
    "Evaluating: 100%|█████████████████████████████████████████████████████████████| 124/124 [00:11<00:00, 10.38batch/s, Loss=0.116, Accuracy=0.953] \n",
    "Train Loss: 0.1416\n",
    "Validation Loss: 0.1184, Validation Accuracy: 0.9525\n",
    "Epoch 3/13\n",
    "Training: 100%|███████████████████████████████████████████████████████████████████████████████| 495/495 [02:20<00:00,  3.53batch/s, Loss=0.198] \n",
    "Evaluating: 100%|█████████████████████████████████████████████████████████████| 124/124 [00:11<00:00, 10.42batch/s, Loss=0.123, Accuracy=0.953] \n",
    "Train Loss: 0.1323\n",
    "Validation Loss: 0.1168, Validation Accuracy: 0.9525\n",
    "Epoch 4/13\n",
    "Training: 100%|████████████████████████████████████████████████████████████████████████████████| 495/495 [02:21<00:00,  3.51batch/s, Loss=0.22] \n",
    "Evaluating: 100%|█████████████████████████████████████████████████████████████| 124/124 [00:12<00:00, 10.23batch/s, Loss=0.119, Accuracy=0.953] \n",
    "Train Loss: 0.1310\n",
    "Validation Loss: 0.1166, Validation Accuracy: 0.9525\n",
    "Epoch 5/13\n",
    "Training: 100%|██████████████████████████████████████████████████████████████████████████████| 495/495 [02:20<00:00,  3.53batch/s, Loss=0.0962] \n",
    "Evaluating: 100%|█████████████████████████████████████████████████████████████| 124/124 [00:11<00:00, 10.40batch/s, Loss=0.119, Accuracy=0.953] \n",
    "Train Loss: 0.1300\n",
    "Validation Loss: 0.1166, Validation Accuracy: 0.9525\n",
    "Epoch 6/13\n",
    "Training: 100%|███████████████████████████████████████████████████████████████████████████████| 495/495 [02:20<00:00,  3.53batch/s, Loss=0.136] \n",
    "Evaluating: 100%|█████████████████████████████████████████████████████████████| 124/124 [00:11<00:00, 10.41batch/s, Loss=0.119, Accuracy=0.953] \n",
    "Train Loss: 0.1283\n",
    "Validation Loss: 0.1166, Validation Accuracy: 0.9525\n",
    "Epoch 7/13\n",
    "Training: 100%|███████████████████████████████████████████████████████████████████████████████| 495/495 [02:20<00:00,  3.53batch/s, Loss=0.251] \n",
    "Evaluating: 100%|█████████████████████████████████████████████████████████████| 124/124 [00:11<00:00, 10.38batch/s, Loss=0.119, Accuracy=0.953] \n",
    "Train Loss: 0.1307\n",
    "Validation Loss: 0.1166, Validation Accuracy: 0.9525\n",
    "Epoch 8/13\n",
    "Training: 100%|███████████████████████████████████████████████████████████████████████████████| 495/495 [02:20<00:00,  3.53batch/s, Loss=0.212] \n",
    "Evaluating: 100%|█████████████████████████████████████████████████████████████| 124/124 [00:11<00:00, 10.40batch/s, Loss=0.119, Accuracy=0.953] \n",
    "Train Loss: 0.1308\n",
    "Validation Loss: 0.1166, Validation Accuracy: 0.9525\n",
    "Epoch 9/13\n",
    "Training: 100%|███████████████████████████████████████████████████████████████████████████████| 495/495 [02:20<00:00,  3.53batch/s, Loss=0.249] \n",
    "Evaluating: 100%|█████████████████████████████████████████████████████████████| 124/124 [00:11<00:00, 10.42batch/s, Loss=0.119, Accuracy=0.953] \n",
    "Train Loss: 0.1304\n",
    "Validation Loss: 0.1166, Validation Accuracy: 0.9525\n",
    "Epoch 10/13\n",
    "Training: 100%|████████████████████████████████████████████████████████████████████████████████| 495/495 [02:20<00:00,  3.53batch/s, Loss=0.13] \n",
    "Evaluating: 100%|█████████████████████████████████████████████████████████████| 124/124 [00:11<00:00, 10.41batch/s, Loss=0.119, Accuracy=0.953] \n",
    "Train Loss: 0.1304\n",
    "Validation Loss: 0.1166, Validation Accuracy: 0.9525\n",
    "Epoch 11/13\n",
    "Training: 100%|██████████████████████████████████████████████████████████████████████████████| 495/495 [02:20<00:00,  3.52batch/s, Loss=0.0106] \n",
    "Evaluating: 100%|█████████████████████████████████████████████████████████████| 124/124 [00:11<00:00, 10.38batch/s, Loss=0.119, Accuracy=0.953] \n",
    "Train Loss: 0.1295\n",
    "Validation Loss: 0.1166, Validation Accuracy: 0.9525\n",
    "Epoch 12/13\n",
    "Training: 100%|██████████████████████████████████████████████████████████████████████████████| 495/495 [02:20<00:00,  3.52batch/s, Loss=0.0452] \n",
    "Evaluating: 100%|█████████████████████████████████████████████████████████████| 124/124 [00:11<00:00, 10.39batch/s, Loss=0.119, Accuracy=0.953] \n",
    "Train Loss: 0.1301\n",
    "Validation Loss: 0.1166, Validation Accuracy: 0.9525\n",
    "Epoch 13/13\n",
    "Training: 100%|██████████████████████████████████████████████████████████████████████████████| 495/495 [02:20<00:00,  3.53batch/s, Loss=0.0695] \n",
    "Evaluating: 100%|█████████████████████████████████████████████████████████████| 124/124 [00:11<00:00, 10.40batch/s, Loss=0.119, Accuracy=0.953] \n",
    "Train Loss: 0.1302\n",
    "Validation Loss: 0.1166, Validation Accuracy: 0.9525\n",
    "Evaluating: 100%|█████████████████████████████████████████████████████████████| 124/124 [00:11<00:00, 10.40batch/s, Loss=0.119, Accuracy=0.953] \n",
    "Test Loss: 0.1166, Test Accuracy: 0.9525\n",
    "\n",
    "Evaluation Metrics:\n",
    "Accuracy: 0.9525252525252526\n",
    "Precision: 0.9597215391745547\n",
    "Recall: 0.9525252525252526\n",
    "F1-score: 0.9544428708916103"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
